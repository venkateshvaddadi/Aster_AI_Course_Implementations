{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "M_OLSkbSBOPD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.mobilenet import mobilenetv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from models.resnet import ResNet50\n",
    "#model=ResNet50(num_classes=3, channels=3)\n",
    "#model=model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mobilenet v2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "f20rQhwMBH3x"
   },
   "outputs": [],
   "source": [
    "model=mobilenetv2(num_classes=3)\n",
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1722151692928,
     "user": {
      "displayName": "venkatesh vaddadi",
      "userId": "14864650657704592599"
     },
     "user_tz": -330
    },
    "id": "J1Z_F9MLCoHH",
    "outputId": "a5353d3e-f5c3-4917-e1fc-424a74b1e4ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traing data\n",
      "   Unnamed: 0                                         image_path  \\\n",
      "0        5758  ./processed_data/pocus_videos_to_images/convex...   \n",
      "1        4244  ./processed_data/pocus_videos_to_images/convex...   \n",
      "2        9517  ./processed_data/pocus_videos_to_images/convex...   \n",
      "3         415  ./processed_data/pocus_videos_to_images/linear...   \n",
      "4       12024  ./processed_data/pocus_videos_to_images/convex...   \n",
      "\n",
      "                 label  \n",
      "0                COVID  \n",
      "1              healthy  \n",
      "2                COVID  \n",
      "3              healthy  \n",
      "4  bacterial pneumonia  \n",
      "stastics of the given data:\n",
      "COVID                  3919\n",
      "healthy                3697\n",
      "bacterial pneumonia    2733\n",
      "viral pneumonia         131\n",
      "Name: label, dtype: int64\n",
      "####################################################################################################\n",
      "validation data\n",
      "   Unnamed: 0                                         image_path  \\\n",
      "0       11813  ./processed_data/pocus_videos_to_images/convex...   \n",
      "1        9247  ./processed_data/pocus_videos_to_images/convex...   \n",
      "2       10128  ./processed_data/pocus_videos_to_images/convex...   \n",
      "3        2310  ./processed_data/pocus_videos_to_images/convex...   \n",
      "4        6786  ./processed_data/pocus_videos_to_images/convex...   \n",
      "\n",
      "                 label  \n",
      "0  bacterial pneumonia  \n",
      "1                COVID  \n",
      "2                COVID  \n",
      "3              healthy  \n",
      "4                COVID  \n",
      "stastics of the given data:\n",
      "COVID                  509\n",
      "healthy                439\n",
      "bacterial pneumonia    352\n",
      "viral pneumonia         10\n",
      "Name: label, dtype: int64\n",
      "####################################################################################################\n",
      "test data\n",
      "   Unnamed: 0                                         image_path  \\\n",
      "0        8570  ./processed_data/pocus_videos_to_images/convex...   \n",
      "1       12592  ./processed_data/pocus_videos_to_images/convex...   \n",
      "2         424  ./processed_data/pocus_videos_to_images/linear...   \n",
      "3        8086  ./processed_data/pocus_videos_to_images/convex...   \n",
      "4        6800  ./processed_data/pocus_videos_to_images/convex...   \n",
      "\n",
      "                 label  \n",
      "0                COVID  \n",
      "1  bacterial pneumonia  \n",
      "2              healthy  \n",
      "3                COVID  \n",
      "4                COVID  \n",
      "stastics of the given data:\n",
      "healthy                503\n",
      "COVID                  456\n",
      "bacterial pneumonia    333\n",
      "viral pneumonia         18\n",
      "Name: label, dtype: int64\n",
      "####################################################################################################\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print('traing data')\n",
    "data = pd.read_csv('./csv_files/data_train.csv')\n",
    "\n",
    "print(data.head())\n",
    "# Print the statastis of the given data\n",
    "print(\"stastics of the given data:\")\n",
    "print(data['label'].value_counts())\n",
    "print('#'*100)\n",
    "\n",
    "print('validation data')\n",
    "\n",
    "data = pd.read_csv('./csv_files/data_valid.csv')\n",
    "\n",
    "print(data.head())\n",
    "# Print the statastis of the given data\n",
    "print(\"stastics of the given data:\")\n",
    "print(data['label'].value_counts())\n",
    "print('#'*100)\n",
    "\n",
    "print('test data')\n",
    "\n",
    "data = pd.read_csv('./csv_files/data_test.csv')\n",
    "\n",
    "print(data.head())\n",
    "# Print the statastis of the given data\n",
    "print(\"stastics of the given data:\")\n",
    "print(data['label'].value_counts())\n",
    "print('#'*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L0nLytpjCgZF"
   },
   "source": [
    "# Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ISZwsT9MRzwg"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Custom Dataset class for classification\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.data = pd.read_csv(csv_file, usecols=['image_path', 'label'])\n",
    "        self.transform = transform\n",
    "        self.class_to_int = {\"COVID\": 0, \"healthy\": 1, \"bacterial pneumonia\": 2,\"viral pneumonia\": 2}  # Mapping class names to integers\n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        image_path = self.data['image_path'][idx]\n",
    "        label = self.class_to_int[self.data['label'][idx]]  # Convert class label to integer\n",
    "\n",
    "        # Load image using PIL\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        # Convert PIL Image to NumPy array\n",
    "        #image = np.array(image)\n",
    "        #image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        #print(image.shape,label)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        image=image[:3,:,:]\n",
    "\n",
    "\n",
    "\n",
    "        #print(np.unique(image))\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "xPo0zQB-Pcnf"
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define transformations for data augmentation or normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize image to required size\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6862,
     "status": "ok",
     "timestamp": 1722151773370,
     "user": {
      "displayName": "venkatesh vaddadi",
      "userId": "14864650657704592599"
     },
     "user_tz": -330
    },
    "id": "OQgQBIa0R2zJ",
    "outputId": "6fa38740-b6cc-415d-988a-8acbb355b1f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /home/venkatesh/anaconda3/envs/venkatesh_pytorch_updated_110/lib/python3.9/site-packages (4.64.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1722151773370,
     "user": {
      "displayName": "venkatesh vaddadi",
      "userId": "14864650657704592599"
     },
     "user_tz": -330
    },
    "id": "eRNeYZqWR8cH",
    "outputId": "eefc4d8d-fb7a-4729-9921-e03df941cb40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164\n",
      "1310\n",
      "164\n",
      "164\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming you have a CSV file named 'data.csv' with image paths and class labels\n",
    "train_csv_file = './drive/MyDrive/Aster/Aster_AI_Course/TA_Projects_Session_2_LUNG_USG_Classification/csv_files/data_train.csv'\n",
    "\n",
    "# Create CustomDataset instance\n",
    "dataset = CustomDataset('./csv_files/data_train.csv', transform=transform)\n",
    "train_loader = DataLoader(dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "val_dataset = CustomDataset('./csv_files/data_valid.csv', transform=transform)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "test_dataset = CustomDataset('./csv_files/data_test.csv', transform=transform)\n",
    "test_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "print(len(test_dataloader))\n",
    "print(len(train_loader))\n",
    "print(len(val_dataloader))\n",
    "print(len(test_dataloader))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "O9K9sfF14Fj9"
   },
   "outputs": [],
   "source": [
    "num_classes = 3  # Assuming 3 classes: \"covid\", \"normal\", \"pneumonia\"\n",
    "\n",
    "\n",
    "learning_rate=0.0001\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "executionInfo": {
     "elapsed": 1402734,
     "status": "error",
     "timestamp": 1722154653137,
     "user": {
      "displayName": "venkatesh vaddadi",
      "userId": "14864650657704592599"
     },
     "user_tz": -330
    },
    "id": "MDAOGA2XGaYV",
    "outputId": "90502478-d614-4152-b892-ae0e84166344"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 1310/1310 [01:28<00:00, 14.85it/s, Loss=0.391]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Epoch: 0 Train mean loss: 512.76920052\n",
      "Train Accuracy%:  84.06488549618321 == 8810 / 10480\n",
      "-------------------------------------------------\n",
      "Model saved at: ./saved_models/mymodel_0.pth\n",
      "Epoch [1/50], Loss: 0.3914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 164/164 [00:08<00:00, 19.85it/s, Validation Loss=0.0717]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.0717\n",
      "-------------------------------------------------\n",
      "Epoch: 0 Val mean loss: 11.75519185\n",
      "       valiation Accuracy%:  98.16793893129771 == 1286 / 1310\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|██████████| 1310/1310 [01:27<00:00, 15.01it/s, Loss=0.103]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Epoch: 1 Train mean loss: 134.34982932\n",
      "Train Accuracy%:  96.7175572519084 == 10136 / 10480\n",
      "-------------------------------------------------\n",
      "Model saved at: ./saved_models/mymodel_1.pth\n",
      "Epoch [2/50], Loss: 0.1026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|██████████| 164/164 [00:08<00:00, 20.29it/s, Validation Loss=0.0316]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Loss: 0.0316\n",
      "-------------------------------------------------\n",
      "Epoch: 1 Val mean loss: 5.18992622\n",
      "       valiation Accuracy%:  98.93129770992367 == 1296 / 1310\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: 100%|██████████| 1310/1310 [01:27<00:00, 15.06it/s, Loss=0.0321]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Epoch: 2 Train mean loss: 42.05788799\n",
      "Train Accuracy%:  98.91221374045801 == 10366 / 10480\n",
      "-------------------------------------------------\n",
      "Model saved at: ./saved_models/mymodel_2.pth\n",
      "Epoch [3/50], Loss: 0.0321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: 100%|██████████| 164/164 [00:07<00:00, 20.59it/s, Validation Loss=0.0452]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50], Loss: 0.0452\n",
      "-------------------------------------------------\n",
      "Epoch: 2 Val mean loss: 7.40505459\n",
      "       valiation Accuracy%:  98.70229007633588 == 1293 / 1310\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: 100%|██████████| 1310/1310 [01:27<00:00, 15.05it/s, Loss=0.0254]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Epoch: 3 Train mean loss: 33.23447883\n",
      "Train Accuracy%:  99.24618320610686 == 10401 / 10480\n",
      "-------------------------------------------------\n",
      "Model saved at: ./saved_models/mymodel_3.pth\n",
      "Epoch [4/50], Loss: 0.0254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: 100%|██████████| 164/164 [00:08<00:00, 19.97it/s, Validation Loss=0.0152]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], Loss: 0.0152\n",
      "-------------------------------------------------\n",
      "Epoch: 3 Val mean loss: 2.49756637\n",
      "       valiation Accuracy%:  99.46564885496183 == 1303 / 1310\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50: 100%|██████████| 1310/1310 [01:26<00:00, 15.06it/s, Loss=0.0224]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Epoch: 4 Train mean loss: 29.28618966\n",
      "Train Accuracy%:  99.35114503816794 == 10412 / 10480\n",
      "-------------------------------------------------\n",
      "Model saved at: ./saved_models/mymodel_4.pth\n",
      "Epoch [5/50], Loss: 0.0224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50: 100%|██████████| 164/164 [00:08<00:00, 19.92it/s, Validation Loss=0.0199]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], Loss: 0.0199\n",
      "-------------------------------------------------\n",
      "Epoch: 4 Val mean loss: 3.26956622\n",
      "       valiation Accuracy%:  99.69465648854961 == 1306 / 1310\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50: 100%|██████████| 1310/1310 [01:27<00:00, 15.03it/s, Loss=0.0171]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Epoch: 5 Train mean loss: 22.36459557\n",
      "Train Accuracy%:  99.47519083969466 == 10425 / 10480\n",
      "-------------------------------------------------\n",
      "Model saved at: ./saved_models/mymodel_5.pth\n",
      "Epoch [6/50], Loss: 0.0171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50: 100%|██████████| 164/164 [00:08<00:00, 20.08it/s, Validation Loss=0.0225]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50], Loss: 0.0225\n",
      "-------------------------------------------------\n",
      "Epoch: 5 Val mean loss: 3.69497733\n",
      "       valiation Accuracy%:  99.46564885496183 == 1303 / 1310\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50: 100%|██████████| 1310/1310 [01:26<00:00, 15.09it/s, Loss=0.011] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Epoch: 6 Train mean loss: 14.35764503\n",
      "Train Accuracy%:  99.65648854961832 == 10444 / 10480\n",
      "-------------------------------------------------\n",
      "Model saved at: ./saved_models/mymodel_6.pth\n",
      "Epoch [7/50], Loss: 0.0110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50: 100%|██████████| 164/164 [00:08<00:00, 19.93it/s, Validation Loss=0.0147] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50], Loss: 0.0147\n",
      "-------------------------------------------------\n",
      "Epoch: 6 Val mean loss: 2.41684798\n",
      "       valiation Accuracy%:  99.69465648854961 == 1306 / 1310\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50: 100%|██████████| 1310/1310 [01:26<00:00, 15.10it/s, Loss=0.0195] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Epoch: 7 Train mean loss: 25.53531349\n",
      "Train Accuracy%:  99.41793893129771 == 10419 / 10480\n",
      "-------------------------------------------------\n",
      "Model saved at: ./saved_models/mymodel_7.pth\n",
      "Epoch [8/50], Loss: 0.0195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50: 100%|██████████| 164/164 [00:08<00:00, 20.35it/s, Validation Loss=0.00864]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Loss: 0.0086\n",
      "-------------------------------------------------\n",
      "Epoch: 7 Val mean loss: 1.41705911\n",
      "       valiation Accuracy%:  99.69465648854961 == 1306 / 1310\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50: 100%|██████████| 1310/1310 [01:26<00:00, 15.13it/s, Loss=0.0101] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Epoch: 8 Train mean loss: 13.24678290\n",
      "Train Accuracy%:  99.65648854961832 == 10444 / 10480\n",
      "-------------------------------------------------\n",
      "Model saved at: ./saved_models/mymodel_8.pth\n",
      "Epoch [9/50], Loss: 0.0101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50: 100%|██████████| 164/164 [00:08<00:00, 20.39it/s, Validation Loss=0.0121] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50], Loss: 0.0121\n",
      "-------------------------------------------------\n",
      "Epoch: 8 Val mean loss: 1.97641068\n",
      "       valiation Accuracy%:  99.69465648854961 == 1306 / 1310\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50: 100%|██████████| 1310/1310 [01:27<00:00, 14.97it/s, Loss=0.00944]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Epoch: 9 Train mean loss: 12.36420130\n",
      "Train Accuracy%:  99.66603053435115 == 10445 / 10480\n",
      "-------------------------------------------------\n",
      "Model saved at: ./saved_models/mymodel_9.pth\n",
      "Epoch [10/50], Loss: 0.0094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50: 100%|██████████| 164/164 [00:08<00:00, 20.38it/s, Validation Loss=0.0933]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Loss: 0.0933\n",
      "-------------------------------------------------\n",
      "Epoch: 9 Val mean loss: 15.30647402\n",
      "       valiation Accuracy%:  96.87022900763358 == 1269 / 1310\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50: 100%|██████████| 1310/1310 [01:26<00:00, 15.08it/s, Loss=0.0134] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Epoch: 10 Train mean loss: 17.57857400\n",
      "Train Accuracy%:  99.59923664122137 == 10438 / 10480\n",
      "-------------------------------------------------\n",
      "Model saved at: ./saved_models/mymodel_10.pth\n",
      "Epoch [11/50], Loss: 0.0134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50: 100%|██████████| 164/164 [00:08<00:00, 19.70it/s, Validation Loss=0.0119]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50], Loss: 0.0119\n",
      "-------------------------------------------------\n",
      "Epoch: 10 Val mean loss: 1.94771242\n",
      "       valiation Accuracy%:  99.77099236641222 == 1307 / 1310\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50: 100%|██████████| 1310/1310 [01:27<00:00, 15.03it/s, Loss=0.00541]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Epoch: 11 Train mean loss: 7.08142022\n",
      "Train Accuracy%:  99.8473282442748 == 10464 / 10480\n",
      "-------------------------------------------------\n",
      "Model saved at: ./saved_models/mymodel_11.pth\n",
      "Epoch [12/50], Loss: 0.0054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50: 100%|██████████| 164/164 [00:08<00:00, 20.29it/s, Validation Loss=0.0117] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50], Loss: 0.0117\n",
      "-------------------------------------------------\n",
      "Epoch: 11 Val mean loss: 1.91282011\n",
      "       valiation Accuracy%:  99.77099236641222 == 1307 / 1310\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50: 100%|██████████| 1310/1310 [01:27<00:00, 15.00it/s, Loss=0.00509]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Epoch: 12 Train mean loss: 6.67247287\n",
      "Train Accuracy%:  99.82824427480917 == 10462 / 10480\n",
      "-------------------------------------------------\n",
      "Model saved at: ./saved_models/mymodel_12.pth\n",
      "Epoch [13/50], Loss: 0.0051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50: 100%|██████████| 164/164 [00:08<00:00, 20.13it/s, Validation Loss=0.0136]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50], Loss: 0.0136\n",
      "-------------------------------------------------\n",
      "Epoch: 12 Val mean loss: 2.23697045\n",
      "       valiation Accuracy%:  99.77099236641222 == 1307 / 1310\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50: 100%|██████████| 1310/1310 [01:26<00:00, 15.09it/s, Loss=2.73e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Epoch: 13 Train mean loss: 0.03574299\n",
      "Train Accuracy%:  100.0 == 10480 / 10480\n",
      "-------------------------------------------------\n",
      "Model saved at: ./saved_models/mymodel_13.pth\n",
      "Epoch [14/50], Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50: 100%|██████████| 164/164 [00:08<00:00, 20.20it/s, Validation Loss=0.0143]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50], Loss: 0.0143\n",
      "-------------------------------------------------\n",
      "Epoch: 13 Val mean loss: 2.34780596\n",
      "       valiation Accuracy%:  99.77099236641222 == 1307 / 1310\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50: 100%|██████████| 1310/1310 [01:27<00:00, 15.04it/s, Loss=1.12e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Epoch: 14 Train mean loss: 0.01467795\n",
      "Train Accuracy%:  100.0 == 10480 / 10480\n",
      "-------------------------------------------------\n",
      "Model saved at: ./saved_models/mymodel_14.pth\n",
      "Epoch [15/50], Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50: 100%|██████████| 164/164 [00:08<00:00, 20.31it/s, Validation Loss=0.0147]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50], Loss: 0.0147\n",
      "-------------------------------------------------\n",
      "Epoch: 14 Val mean loss: 2.41897120\n",
      "       valiation Accuracy%:  99.77099236641222 == 1307 / 1310\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/50: 100%|██████████| 1310/1310 [01:27<00:00, 15.03it/s, Loss=5.39e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Epoch: 15 Train mean loss: 0.00706250\n",
      "Train Accuracy%:  100.0 == 10480 / 10480\n",
      "-------------------------------------------------\n",
      "Model saved at: ./saved_models/mymodel_15.pth\n",
      "Epoch [16/50], Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/50: 100%|██████████| 164/164 [00:08<00:00, 20.18it/s, Validation Loss=0.0153]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50], Loss: 0.0153\n",
      "-------------------------------------------------\n",
      "Epoch: 15 Val mean loss: 2.50543768\n",
      "       valiation Accuracy%:  99.77099236641222 == 1307 / 1310\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/50: 100%|██████████| 1310/1310 [01:27<00:00, 15.01it/s, Loss=2.55e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Epoch: 16 Train mean loss: 0.00333904\n",
      "Train Accuracy%:  100.0 == 10480 / 10480\n",
      "-------------------------------------------------\n",
      "Model saved at: ./saved_models/mymodel_16.pth\n",
      "Epoch [17/50], Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/50: 100%|██████████| 164/164 [00:08<00:00, 20.04it/s, Validation Loss=0.0158]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50], Loss: 0.0158\n",
      "-------------------------------------------------\n",
      "Epoch: 16 Val mean loss: 2.58360489\n",
      "       valiation Accuracy%:  99.77099236641222 == 1307 / 1310\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/50: 100%|██████████| 1310/1310 [01:27<00:00, 15.03it/s, Loss=1.25e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Epoch: 17 Train mean loss: 0.00163190\n",
      "Train Accuracy%:  100.0 == 10480 / 10480\n",
      "-------------------------------------------------\n",
      "Model saved at: ./saved_models/mymodel_17.pth\n",
      "Epoch [18/50], Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/50: 100%|██████████| 164/164 [00:08<00:00, 20.39it/s, Validation Loss=0.0162]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50], Loss: 0.0162\n",
      "-------------------------------------------------\n",
      "Epoch: 17 Val mean loss: 2.65100105\n",
      "       valiation Accuracy%:  99.77099236641222 == 1307 / 1310\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/50: 100%|██████████| 1310/1310 [01:27<00:00, 15.01it/s, Loss=6.17e-7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Epoch: 18 Train mean loss: 0.00080771\n",
      "Train Accuracy%:  100.0 == 10480 / 10480\n",
      "-------------------------------------------------\n",
      "Model saved at: ./saved_models/mymodel_18.pth\n",
      "Epoch [19/50], Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/50: 100%|██████████| 164/164 [00:08<00:00, 20.00it/s, Validation Loss=0.0166]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50], Loss: 0.0166\n",
      "-------------------------------------------------\n",
      "Epoch: 18 Val mean loss: 2.71702308\n",
      "       valiation Accuracy%:  99.77099236641222 == 1307 / 1310\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/50: 100%|██████████| 1310/1310 [01:26<00:00, 15.08it/s, Loss=3.06e-7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Epoch: 19 Train mean loss: 0.00040102\n",
      "Train Accuracy%:  100.0 == 10480 / 10480\n",
      "-------------------------------------------------\n",
      "Model saved at: ./saved_models/mymodel_19.pth\n",
      "Epoch [20/50], Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/50: 100%|██████████| 164/164 [00:08<00:00, 20.09it/s, Validation Loss=0.0169]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50], Loss: 0.0169\n",
      "-------------------------------------------------\n",
      "Epoch: 19 Val mean loss: 2.77659962\n",
      "       valiation Accuracy%:  99.77099236641222 == 1307 / 1310\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/50: 100%|██████████| 1310/1310 [01:26<00:00, 15.11it/s, Loss=1.51e-7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Epoch: 20 Train mean loss: 0.00019737\n",
      "Train Accuracy%:  100.0 == 10480 / 10480\n",
      "-------------------------------------------------\n",
      "Model saved at: ./saved_models/mymodel_20.pth\n",
      "Epoch [21/50], Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/50: 100%|██████████| 164/164 [00:08<00:00, 20.13it/s, Validation Loss=0.0173]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50], Loss: 0.0173\n",
      "-------------------------------------------------\n",
      "Epoch: 20 Val mean loss: 2.83794606\n",
      "       valiation Accuracy%:  99.77099236641222 == 1307 / 1310\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/50: 100%|██████████| 1310/1310 [01:26<00:00, 15.07it/s, Loss=7.36e-8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Epoch: 21 Train mean loss: 0.00009641\n",
      "Train Accuracy%:  100.0 == 10480 / 10480\n",
      "-------------------------------------------------\n",
      "Model saved at: ./saved_models/mymodel_21.pth\n",
      "Epoch [22/50], Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/50: 100%|██████████| 164/164 [00:08<00:00, 19.97it/s, Validation Loss=0.0176]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50], Loss: 0.0176\n",
      "-------------------------------------------------\n",
      "Epoch: 21 Val mean loss: 2.89260359\n",
      "       valiation Accuracy%:  99.77099236641222 == 1307 / 1310\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/50: 100%|██████████| 1310/1310 [01:27<00:00, 15.06it/s, Loss=3.59e-8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Epoch: 22 Train mean loss: 0.00004701\n",
      "Train Accuracy%:  100.0 == 10480 / 10480\n",
      "-------------------------------------------------\n",
      "Model saved at: ./saved_models/mymodel_22.pth\n",
      "Epoch [23/50], Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/50: 100%|██████████| 164/164 [00:08<00:00, 20.11it/s, Validation Loss=0.0179]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/50], Loss: 0.0179\n",
      "-------------------------------------------------\n",
      "Epoch: 22 Val mean loss: 2.94309393\n",
      "       valiation Accuracy%:  99.77099236641222 == 1307 / 1310\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/50: 100%|██████████| 1310/1310 [01:27<00:00, 14.99it/s, Loss=1.72e-8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Epoch: 23 Train mean loss: 0.00002253\n",
      "Train Accuracy%:  100.0 == 10480 / 10480\n",
      "-------------------------------------------------\n",
      "Model saved at: ./saved_models/mymodel_23.pth\n",
      "Epoch [24/50], Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/50: 100%|██████████| 164/164 [00:08<00:00, 20.13it/s, Validation Loss=0.0182]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50], Loss: 0.0182\n",
      "-------------------------------------------------\n",
      "Epoch: 23 Val mean loss: 2.99150423\n",
      "       valiation Accuracy%:  99.77099236641222 == 1307 / 1310\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/50: 100%|██████████| 1310/1310 [01:27<00:00, 15.01it/s, Loss=7.99e-9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Epoch: 24 Train mean loss: 0.00001046\n",
      "Train Accuracy%:  100.0 == 10480 / 10480\n",
      "-------------------------------------------------\n",
      "Model saved at: ./saved_models/mymodel_24.pth\n",
      "Epoch [25/50], Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/50: 100%|██████████| 164/164 [00:08<00:00, 20.10it/s, Validation Loss=0.0185]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50], Loss: 0.0185\n",
      "-------------------------------------------------\n",
      "Epoch: 24 Val mean loss: 3.02668212\n",
      "       valiation Accuracy%:  99.77099236641222 == 1307 / 1310\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/50: 100%|██████████| 1310/1310 [01:27<00:00, 14.96it/s, Loss=3.67e-9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Epoch: 25 Train mean loss: 0.00000481\n",
      "Train Accuracy%:  100.0 == 10480 / 10480\n",
      "-------------------------------------------------\n",
      "Model saved at: ./saved_models/mymodel_25.pth\n",
      "Epoch [26/50], Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/50: 100%|██████████| 164/164 [00:08<00:00, 20.01it/s, Validation Loss=0.0187]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/50], Loss: 0.0187\n",
      "-------------------------------------------------\n",
      "Epoch: 25 Val mean loss: 3.06644221\n",
      "       valiation Accuracy%:  99.77099236641222 == 1307 / 1310\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/50: 100%|██████████| 1310/1310 [01:26<00:00, 15.08it/s, Loss=1.46e-9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Epoch: 26 Train mean loss: 0.00000191\n",
      "Train Accuracy%:  100.0 == 10480 / 10480\n",
      "-------------------------------------------------\n",
      "Model saved at: ./saved_models/mymodel_26.pth\n",
      "Epoch [27/50], Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/50: 100%|██████████| 164/164 [00:08<00:00, 20.39it/s, Validation Loss=0.0191]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50], Loss: 0.0191\n",
      "-------------------------------------------------\n",
      "Epoch: 26 Val mean loss: 3.13311352\n",
      "       valiation Accuracy%:  99.77099236641222 == 1307 / 1310\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/50: 100%|██████████| 1310/1310 [01:27<00:00, 15.03it/s, Loss=4.55e-10]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Epoch: 27 Train mean loss: 0.00000060\n",
      "Train Accuracy%:  100.0 == 10480 / 10480\n",
      "-------------------------------------------------\n",
      "Model saved at: ./saved_models/mymodel_27.pth\n",
      "Epoch [28/50], Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/50: 100%|██████████| 164/164 [00:08<00:00, 20.00it/s, Validation Loss=0.0194]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/50], Loss: 0.0194\n",
      "-------------------------------------------------\n",
      "Epoch: 27 Val mean loss: 3.18413744\n",
      "       valiation Accuracy%:  99.77099236641222 == 1307 / 1310\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/50: 100%|██████████| 1310/1310 [01:26<00:00, 15.08it/s, Loss=9.1e-11] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Epoch: 28 Train mean loss: 0.00000012\n",
      "Train Accuracy%:  100.0 == 10480 / 10480\n",
      "-------------------------------------------------\n",
      "Model saved at: ./saved_models/mymodel_28.pth\n",
      "Epoch [29/50], Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/50: 100%|██████████| 164/164 [00:08<00:00, 20.29it/s, Validation Loss=0.0199]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50], Loss: 0.0199\n",
      "-------------------------------------------------\n",
      "Epoch: 28 Val mean loss: 3.26794279\n",
      "       valiation Accuracy%:  99.77099236641222 == 1307 / 1310\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/50: 100%|██████████| 1310/1310 [01:26<00:00, 15.06it/s, Loss=2.27e-11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Epoch: 29 Train mean loss: 0.00000003\n",
      "Train Accuracy%:  100.0 == 10480 / 10480\n",
      "-------------------------------------------------\n",
      "Model saved at: ./saved_models/mymodel_29.pth\n",
      "Epoch [30/50], Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/50: 100%|██████████| 164/164 [00:08<00:00, 19.59it/s, Validation Loss=0.0202]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50], Loss: 0.0202\n",
      "-------------------------------------------------\n",
      "Epoch: 29 Val mean loss: 3.31726165\n",
      "       valiation Accuracy%:  99.77099236641222 == 1307 / 1310\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/50: 100%|██████████| 1310/1310 [01:27<00:00, 14.95it/s, Loss=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Epoch: 30 Train mean loss: 0.00000000\n",
      "Train Accuracy%:  100.0 == 10480 / 10480\n",
      "-------------------------------------------------\n",
      "Model saved at: ./saved_models/mymodel_30.pth\n",
      "Epoch [31/50], Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/50: 100%|██████████| 164/164 [00:08<00:00, 20.19it/s, Validation Loss=0.0206]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50], Loss: 0.0206\n",
      "-------------------------------------------------\n",
      "Epoch: 30 Val mean loss: 3.38463893\n",
      "       valiation Accuracy%:  99.77099236641222 == 1307 / 1310\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/50:   9%|▉         | 123/1310 [00:08<01:19, 14.97it/s, Loss=0]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Create tqdm progress bar\u001b[39;00m\n\u001b[1;32m     22\u001b[0m progress_bar \u001b[38;5;241m=\u001b[39m tqdm(\u001b[38;5;28menumerate\u001b[39m(train_loader), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (images, labels) \u001b[38;5;129;01min\u001b[39;00m progress_bar:\n\u001b[1;32m     25\u001b[0m     images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     26\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/envs/venkatesh_pytorch_updated_110/lib/python3.9/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/venkatesh_pytorch_updated_110/lib/python3.9/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/venkatesh_pytorch_updated_110/lib/python3.9/site-packages/torch/utils/data/dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    569\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    572\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/venkatesh_pytorch_updated_110/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/venkatesh_pytorch_updated_110/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Convert PIL Image to NumPy array\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m#image = np.array(image)\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m#image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[0;32m---> 36\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m#print(image.shape,label)\u001b[39;00m\n\u001b[1;32m     42\u001b[0m image\u001b[38;5;241m=\u001b[39mimage[:\u001b[38;5;241m3\u001b[39m,:,:]\n",
      "File \u001b[0;32m~/anaconda3/envs/venkatesh_pytorch_updated_110/lib/python3.9/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/anaconda3/envs/venkatesh_pytorch_updated_110/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/venkatesh_pytorch_updated_110/lib/python3.9/site-packages/torchvision/transforms/transforms.py:349\u001b[0m, in \u001b[0;36mResize.forward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;124;03m        img (PIL Image or Tensor): Image to be scaled.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;124;03m        PIL Image or Tensor: Rescaled image.\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mantialias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/venkatesh_pytorch_updated_110/lib/python3.9/site-packages/torchvision/transforms/functional.py:436\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    434\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnti-alias option is always applied for PIL Image input. Argument antialias is ignored.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    435\u001b[0m     pil_interpolation \u001b[38;5;241m=\u001b[39m pil_modes_mapping[interpolation]\n\u001b[0;32m--> 436\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_pil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpil_interpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F_t\u001b[38;5;241m.\u001b[39mresize(img, size\u001b[38;5;241m=\u001b[39msize, interpolation\u001b[38;5;241m=\u001b[39minterpolation\u001b[38;5;241m.\u001b[39mvalue, max_size\u001b[38;5;241m=\u001b[39mmax_size, antialias\u001b[38;5;241m=\u001b[39mantialias)\n",
      "File \u001b[0;32m~/anaconda3/envs/venkatesh_pytorch_updated_110/lib/python3.9/site-packages/torchvision/transforms/functional_pil.py:265\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    262\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_size should only be passed if size specifies the length of the smaller edge, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    263\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi.e. size should be an int or a sequence of length 1 in torchscript mode.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    264\u001b[0m     )\n\u001b[0;32m--> 265\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/venkatesh_pytorch_updated_110/lib/python3.9/site-packages/PIL/Image.py:1961\u001b[0m, in \u001b[0;36mImage.resize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   1958\u001b[0m     im \u001b[38;5;241m=\u001b[39m im\u001b[38;5;241m.\u001b[39mresize(size, resample, box)\n\u001b[1;32m   1959\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m im\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode)\n\u001b[0;32m-> 1961\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reducing_gap \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m resample \u001b[38;5;241m!=\u001b[39m NEAREST:\n\u001b[1;32m   1964\u001b[0m     factor_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m((box[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m size[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m reducing_gap) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/venkatesh_pytorch_updated_110/lib/python3.9/site-packages/PIL/ImageFile.py:253\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m    248\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage file is truncated \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    249\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(b)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m bytes not processed)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    250\u001b[0m         )\n\u001b[1;32m    252\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[0;32m--> 253\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train your model\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define your training function\n",
    "model.train()\n",
    "train_losses = []  # List to store training losses\n",
    "val_losses = []  # List to store validaion losses\n",
    "\n",
    "num_epochs=50\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    validation_loss=0.0\n",
    "    \n",
    "    y_true_train = []\n",
    "    y_pred_train = []\n",
    "\n",
    "\n",
    "    # Create tqdm progress bar\n",
    "    progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f'Epoch {epoch + 1}/{num_epochs}')\n",
    "\n",
    "    for batch_idx, (images, labels) in progress_bar:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        #images=images/255\n",
    "        #print(torch.unique(images))\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        y_pred_train.extend(outputs.detach().argmax(dim=-1).tolist())\n",
    "        y_true_train.extend(labels.detach().tolist())\n",
    "\n",
    "        \n",
    "        # Update progress bar description with current loss\n",
    "        progress_bar.set_postfix({'Loss': running_loss / (batch_idx + 1)})\n",
    "\n",
    "        \n",
    "    total_correct = len([True for x, y in zip(y_pred_train, y_true_train) if x==y])\n",
    "    total = len(y_pred_train)\n",
    "    accuracy = total_correct * 100 / total\n",
    "    print(\"-------------------------------------------------\")\n",
    "    print(\"Epoch: {} Train mean loss: {:.8f}\".format(epoch, running_loss))\n",
    "    print(\"Train Accuracy%: \", accuracy, \"==\", total_correct, \"/\", total)\n",
    "    print(\"-------------------------------------------------\")\n",
    "        \n",
    "    save_path='./saved_models/mymodel_'+str(epoch)+'.pth'\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f'Model saved at: {save_path}')\n",
    "\n",
    "    # storing the train losses\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(epoch_loss)\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "\n",
    "    progress_bar = tqdm(enumerate(val_dataloader), total=len(val_dataloader), desc=f'Epoch {epoch + 1}/{num_epochs}')\n",
    "\n",
    "    y_true_val = []\n",
    "    y_pred_val = []\n",
    "\n",
    "    \n",
    "    model.eval()\n",
    "    for batch_idx, (images, labels) in progress_bar:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        #images=images/255\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        validation_loss += loss.item()\n",
    "\n",
    "        y_pred_val.extend(outputs.detach().argmax(dim=-1).tolist())\n",
    "        y_true_val.extend(labels.detach().tolist())\n",
    "\n",
    "        \n",
    "        \n",
    "        # Update progress bar description with current loss\n",
    "        progress_bar.set_postfix({'Validation Loss': validation_loss / (batch_idx + 1)})\n",
    "\n",
    "    # storing the validation losses\n",
    "\n",
    "    epoch_loss = validation_loss / len(val_dataloader)\n",
    "    val_losses.append(epoch_loss)\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "    \n",
    "    total_correct = len([True for x, y in zip(y_pred_val, y_true_val) if x==y])\n",
    "    total = len(y_true_val)\n",
    "    accuracy = total_correct * 100 / total\n",
    "\n",
    "    print(\"-------------------------------------------------\")\n",
    "    print(\"Epoch: {} Val mean loss: {:.8f}\".format(epoch, validation_loss))\n",
    "    print(\"       valiation Accuracy%: \", accuracy, \"==\", total_correct, \"/\", total)\n",
    "    print(\"-------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "2GMcEDHbSNj0"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training and validation losses\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_epoch: 7\n"
     ]
    }
   ],
   "source": [
    "best_epoch=np.argmin(val_losses)\n",
    "print('best_epoch:',best_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i5Dttl9Poa-C"
   },
   "source": [
    "# number of parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total params: 2,227,715\n",
    "\n",
    "Trainable params: 2,227,715\n",
    "\n",
    "Non-trainable params: 0\n",
    "----------------------------------------------------------------\n",
    "Input size (MB): 0.57\n",
    "\n",
    "Forward/backward pass size (MB): 152.86\n",
    "\n",
    "Params size (MB): 8.50\n",
    "\n",
    "Estimated Total Size (MB): 161.93"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computational complexity: 911.67 MMac\n",
    "\n",
    "\n",
    "Computational complexity: 1823.34 MFlops\n",
    "\n",
    "Number of parameters: 2.23 M "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3620,
     "status": "ok",
     "timestamp": 1722149595965,
     "user": {
      "displayName": "venkatesh vaddadi",
      "userId": "14864650657704592599"
     },
     "user_tz": -330
    },
    "id": "hh81HlXpayBj",
    "outputId": "38772ac0-a5f4-47b2-9df7-1a9db90fb2b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 112, 112]             864\n",
      "       BatchNorm2d-2         [-1, 32, 112, 112]              64\n",
      "             ReLU6-3         [-1, 32, 112, 112]               0\n",
      "            Conv2d-4         [-1, 32, 112, 112]             288\n",
      "       BatchNorm2d-5         [-1, 32, 112, 112]              64\n",
      "             ReLU6-6         [-1, 32, 112, 112]               0\n",
      "            Conv2d-7         [-1, 16, 112, 112]             512\n",
      "       BatchNorm2d-8         [-1, 16, 112, 112]              32\n",
      "  InvertedResidual-9         [-1, 16, 112, 112]               0\n",
      "           Conv2d-10         [-1, 96, 112, 112]           1,536\n",
      "      BatchNorm2d-11         [-1, 96, 112, 112]             192\n",
      "            ReLU6-12         [-1, 96, 112, 112]               0\n",
      "           Conv2d-13           [-1, 96, 56, 56]             864\n",
      "      BatchNorm2d-14           [-1, 96, 56, 56]             192\n",
      "            ReLU6-15           [-1, 96, 56, 56]               0\n",
      "           Conv2d-16           [-1, 24, 56, 56]           2,304\n",
      "      BatchNorm2d-17           [-1, 24, 56, 56]              48\n",
      " InvertedResidual-18           [-1, 24, 56, 56]               0\n",
      "           Conv2d-19          [-1, 144, 56, 56]           3,456\n",
      "      BatchNorm2d-20          [-1, 144, 56, 56]             288\n",
      "            ReLU6-21          [-1, 144, 56, 56]               0\n",
      "           Conv2d-22          [-1, 144, 56, 56]           1,296\n",
      "      BatchNorm2d-23          [-1, 144, 56, 56]             288\n",
      "            ReLU6-24          [-1, 144, 56, 56]               0\n",
      "           Conv2d-25           [-1, 24, 56, 56]           3,456\n",
      "      BatchNorm2d-26           [-1, 24, 56, 56]              48\n",
      " InvertedResidual-27           [-1, 24, 56, 56]               0\n",
      "           Conv2d-28          [-1, 144, 56, 56]           3,456\n",
      "      BatchNorm2d-29          [-1, 144, 56, 56]             288\n",
      "            ReLU6-30          [-1, 144, 56, 56]               0\n",
      "           Conv2d-31          [-1, 144, 28, 28]           1,296\n",
      "      BatchNorm2d-32          [-1, 144, 28, 28]             288\n",
      "            ReLU6-33          [-1, 144, 28, 28]               0\n",
      "           Conv2d-34           [-1, 32, 28, 28]           4,608\n",
      "      BatchNorm2d-35           [-1, 32, 28, 28]              64\n",
      " InvertedResidual-36           [-1, 32, 28, 28]               0\n",
      "           Conv2d-37          [-1, 192, 28, 28]           6,144\n",
      "      BatchNorm2d-38          [-1, 192, 28, 28]             384\n",
      "            ReLU6-39          [-1, 192, 28, 28]               0\n",
      "           Conv2d-40          [-1, 192, 28, 28]           1,728\n",
      "      BatchNorm2d-41          [-1, 192, 28, 28]             384\n",
      "            ReLU6-42          [-1, 192, 28, 28]               0\n",
      "           Conv2d-43           [-1, 32, 28, 28]           6,144\n",
      "      BatchNorm2d-44           [-1, 32, 28, 28]              64\n",
      " InvertedResidual-45           [-1, 32, 28, 28]               0\n",
      "           Conv2d-46          [-1, 192, 28, 28]           6,144\n",
      "      BatchNorm2d-47          [-1, 192, 28, 28]             384\n",
      "            ReLU6-48          [-1, 192, 28, 28]               0\n",
      "           Conv2d-49          [-1, 192, 28, 28]           1,728\n",
      "      BatchNorm2d-50          [-1, 192, 28, 28]             384\n",
      "            ReLU6-51          [-1, 192, 28, 28]               0\n",
      "           Conv2d-52           [-1, 32, 28, 28]           6,144\n",
      "      BatchNorm2d-53           [-1, 32, 28, 28]              64\n",
      " InvertedResidual-54           [-1, 32, 28, 28]               0\n",
      "           Conv2d-55          [-1, 192, 28, 28]           6,144\n",
      "      BatchNorm2d-56          [-1, 192, 28, 28]             384\n",
      "            ReLU6-57          [-1, 192, 28, 28]               0\n",
      "           Conv2d-58          [-1, 192, 14, 14]           1,728\n",
      "      BatchNorm2d-59          [-1, 192, 14, 14]             384\n",
      "            ReLU6-60          [-1, 192, 14, 14]               0\n",
      "           Conv2d-61           [-1, 64, 14, 14]          12,288\n",
      "      BatchNorm2d-62           [-1, 64, 14, 14]             128\n",
      " InvertedResidual-63           [-1, 64, 14, 14]               0\n",
      "           Conv2d-64          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-65          [-1, 384, 14, 14]             768\n",
      "            ReLU6-66          [-1, 384, 14, 14]               0\n",
      "           Conv2d-67          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-68          [-1, 384, 14, 14]             768\n",
      "            ReLU6-69          [-1, 384, 14, 14]               0\n",
      "           Conv2d-70           [-1, 64, 14, 14]          24,576\n",
      "      BatchNorm2d-71           [-1, 64, 14, 14]             128\n",
      " InvertedResidual-72           [-1, 64, 14, 14]               0\n",
      "           Conv2d-73          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-74          [-1, 384, 14, 14]             768\n",
      "            ReLU6-75          [-1, 384, 14, 14]               0\n",
      "           Conv2d-76          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-77          [-1, 384, 14, 14]             768\n",
      "            ReLU6-78          [-1, 384, 14, 14]               0\n",
      "           Conv2d-79           [-1, 64, 14, 14]          24,576\n",
      "      BatchNorm2d-80           [-1, 64, 14, 14]             128\n",
      " InvertedResidual-81           [-1, 64, 14, 14]               0\n",
      "           Conv2d-82          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-83          [-1, 384, 14, 14]             768\n",
      "            ReLU6-84          [-1, 384, 14, 14]               0\n",
      "           Conv2d-85          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-86          [-1, 384, 14, 14]             768\n",
      "            ReLU6-87          [-1, 384, 14, 14]               0\n",
      "           Conv2d-88           [-1, 64, 14, 14]          24,576\n",
      "      BatchNorm2d-89           [-1, 64, 14, 14]             128\n",
      " InvertedResidual-90           [-1, 64, 14, 14]               0\n",
      "           Conv2d-91          [-1, 384, 14, 14]          24,576\n",
      "      BatchNorm2d-92          [-1, 384, 14, 14]             768\n",
      "            ReLU6-93          [-1, 384, 14, 14]               0\n",
      "           Conv2d-94          [-1, 384, 14, 14]           3,456\n",
      "      BatchNorm2d-95          [-1, 384, 14, 14]             768\n",
      "            ReLU6-96          [-1, 384, 14, 14]               0\n",
      "           Conv2d-97           [-1, 96, 14, 14]          36,864\n",
      "      BatchNorm2d-98           [-1, 96, 14, 14]             192\n",
      " InvertedResidual-99           [-1, 96, 14, 14]               0\n",
      "          Conv2d-100          [-1, 576, 14, 14]          55,296\n",
      "     BatchNorm2d-101          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-102          [-1, 576, 14, 14]               0\n",
      "          Conv2d-103          [-1, 576, 14, 14]           5,184\n",
      "     BatchNorm2d-104          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-105          [-1, 576, 14, 14]               0\n",
      "          Conv2d-106           [-1, 96, 14, 14]          55,296\n",
      "     BatchNorm2d-107           [-1, 96, 14, 14]             192\n",
      "InvertedResidual-108           [-1, 96, 14, 14]               0\n",
      "          Conv2d-109          [-1, 576, 14, 14]          55,296\n",
      "     BatchNorm2d-110          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-111          [-1, 576, 14, 14]               0\n",
      "          Conv2d-112          [-1, 576, 14, 14]           5,184\n",
      "     BatchNorm2d-113          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-114          [-1, 576, 14, 14]               0\n",
      "          Conv2d-115           [-1, 96, 14, 14]          55,296\n",
      "     BatchNorm2d-116           [-1, 96, 14, 14]             192\n",
      "InvertedResidual-117           [-1, 96, 14, 14]               0\n",
      "          Conv2d-118          [-1, 576, 14, 14]          55,296\n",
      "     BatchNorm2d-119          [-1, 576, 14, 14]           1,152\n",
      "           ReLU6-120          [-1, 576, 14, 14]               0\n",
      "          Conv2d-121            [-1, 576, 7, 7]           5,184\n",
      "     BatchNorm2d-122            [-1, 576, 7, 7]           1,152\n",
      "           ReLU6-123            [-1, 576, 7, 7]               0\n",
      "          Conv2d-124            [-1, 160, 7, 7]          92,160\n",
      "     BatchNorm2d-125            [-1, 160, 7, 7]             320\n",
      "InvertedResidual-126            [-1, 160, 7, 7]               0\n",
      "          Conv2d-127            [-1, 960, 7, 7]         153,600\n",
      "     BatchNorm2d-128            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-129            [-1, 960, 7, 7]               0\n",
      "          Conv2d-130            [-1, 960, 7, 7]           8,640\n",
      "     BatchNorm2d-131            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-132            [-1, 960, 7, 7]               0\n",
      "          Conv2d-133            [-1, 160, 7, 7]         153,600\n",
      "     BatchNorm2d-134            [-1, 160, 7, 7]             320\n",
      "InvertedResidual-135            [-1, 160, 7, 7]               0\n",
      "          Conv2d-136            [-1, 960, 7, 7]         153,600\n",
      "     BatchNorm2d-137            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-138            [-1, 960, 7, 7]               0\n",
      "          Conv2d-139            [-1, 960, 7, 7]           8,640\n",
      "     BatchNorm2d-140            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-141            [-1, 960, 7, 7]               0\n",
      "          Conv2d-142            [-1, 160, 7, 7]         153,600\n",
      "     BatchNorm2d-143            [-1, 160, 7, 7]             320\n",
      "InvertedResidual-144            [-1, 160, 7, 7]               0\n",
      "          Conv2d-145            [-1, 960, 7, 7]         153,600\n",
      "     BatchNorm2d-146            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-147            [-1, 960, 7, 7]               0\n",
      "          Conv2d-148            [-1, 960, 7, 7]           8,640\n",
      "     BatchNorm2d-149            [-1, 960, 7, 7]           1,920\n",
      "           ReLU6-150            [-1, 960, 7, 7]               0\n",
      "          Conv2d-151            [-1, 320, 7, 7]         307,200\n",
      "     BatchNorm2d-152            [-1, 320, 7, 7]             640\n",
      "InvertedResidual-153            [-1, 320, 7, 7]               0\n",
      "          Conv2d-154           [-1, 1280, 7, 7]         409,600\n",
      "     BatchNorm2d-155           [-1, 1280, 7, 7]           2,560\n",
      "           ReLU6-156           [-1, 1280, 7, 7]               0\n",
      "AdaptiveAvgPool2d-157           [-1, 1280, 1, 1]               0\n",
      "          Linear-158                    [-1, 3]           3,843\n",
      "================================================================\n",
      "Total params: 2,227,715\n",
      "Trainable params: 2,227,715\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 152.86\n",
      "Params size (MB): 8.50\n",
      "Estimated Total Size (MB): 161.93\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computational complexity: 911.67 MMac\n",
      "Computational complexity: 1823.34 MFlops\n",
      "Number of parameters: 2.23 M  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from ptflops import get_model_complexity_info\n",
    "from pthflops import count_ops\n",
    "\n",
    "macs, params = get_model_complexity_info(model, (3, 448, 320), as_strings=True,print_per_layer_stat=False, verbose=False)\n",
    "# # Extract the numerical value\n",
    "flops = eval(re.findall(r'([\\d.]+)', macs)[0])*2\n",
    "# Extract the unit\n",
    "flops_unit = re.findall(r'([A-Za-z]+)', macs)[0][0]\n",
    "\n",
    "print('Computational complexity: {:<8}'.format(macs))\n",
    "print('Computational complexity: {} {}Flops'.format(flops, flops_unit))\n",
    "print('Number of parameters: {:<8}'.format(params))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 396,
     "status": "ok",
     "timestamp": 1722092520501,
     "user": {
      "displayName": "venkatesh vaddadi",
      "userId": "14864650657704592599"
     },
     "user_tz": -330
    },
    "id": "w_sacd3gtlMe",
    "outputId": "ab2e3264-a5d3-4410-82ce-29109f63fa8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (features): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "        (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "        (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "        (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU6(inplace=True)\n",
       "        (3): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "        (4): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU6(inplace=True)\n",
       "        (6): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (7): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU6(inplace=True)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (classifier): Linear(in_features=1280, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = torch.load('./saved_models/mymodel_7.pth')\n",
    "model.load_state_dict(ckpt)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 164/164 [00:07<00:00, 20.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "TEST Accuracy (%):  99.69465648854961 == 1306 / 1310\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "progress_bar = tqdm(enumerate(test_dataloader), total=len(test_dataloader), desc=f'testing')\n",
    "\n",
    "y_true_val = []\n",
    "y_pred_val = []\n",
    "\n",
    "\n",
    "model.eval()\n",
    "for batch_idx, (images, labels) in progress_bar:\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    #images=images/255\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs = model(images)\n",
    "\n",
    "    y_pred_val.extend(outputs.detach().argmax(dim=-1).tolist())\n",
    "    y_true_val.extend(labels.detach().tolist())\n",
    "\n",
    "\n",
    "\n",
    "    # Update progress bar description with current loss\n",
    "\n",
    "\n",
    "\n",
    "total_correct = len([True for x, y in zip(y_pred_val, y_true_val) if x==y])\n",
    "total = len(y_true_val)\n",
    "accuracy = total_correct * 100 / total\n",
    "\n",
    "print(\"-------------------------------------------------\")\n",
    "print(\"TEST Accuracy (%): \", accuracy, \"==\", total_correct, \"/\", total)\n",
    "print(\"-------------------------------------------------\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
